{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "n400 = pd.read_csv(\"N400_by_trial.csv\")\n",
    "p600 = pd.read_csv(\"P600_by_trial.csv\")\n",
    "spr = pd.read_csv(\"SPR_by_trial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataframe: pd.DataFrame, condition):\n",
    "    \"\"\"\n",
    "    Extracts features from a dataframe of ERPs / SRP's. \n",
    "    \n",
    "    Args:\n",
    "        dataframe: A dataframe of ERPs / SRP's.\n",
    "        condition: The condition to extract features from.\n",
    "    Returns:\n",
    "        A numpy array of features.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = dataframe[dataframe[\"Condition\"] == condition]\n",
    "    features = features.drop([\"Condition\"], axis=1)\n",
    "    features = features.set_index(\"ItemNum\")\n",
    "    features = np.expand_dims(features.to_numpy(), axis=0)\n",
    "    return features\n",
    "\n",
    "n400_control = extract_features(n400, \"control\")\n",
    "n400_script_related = extract_features(n400, \"script-related\")\n",
    "n400_script_unrelated = extract_features(n400, \"script-unrelated\")\n",
    "\n",
    "p600_control = extract_features(p600, \"control\")\n",
    "p600_script_related = extract_features(p600, \"script-related\")\n",
    "p600_script_unrelated = extract_features(p600, \"script-unrelated\")\n",
    "\n",
    "spr_control = extract_features(spr, \"control\")\n",
    "spr_script_related = extract_features(spr, \"script-related\")\n",
    "spr_script_unrelated = extract_features(spr, \"script-unrelated\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemNum: 1\n",
      "ERP's (n400): \n",
      "[-1.79205279 -1.86712636 -1.70394696 -3.9231718  -4.74066061 -4.90966067\n",
      " -2.37030723 -1.98819744 -3.95095261 -3.93343971 -4.15195217 -2.20787836\n",
      " -3.72650287 -2.34174259  0.50864363 -1.46534323 -2.34354867 -2.66679243\n",
      " -0.31249529  0.80925981 -1.85934109 -1.26222229 -1.31437606 -1.49421967\n",
      " -0.46220971 -0.38511491]\n",
      "SPR: [432.36363636]\n"
     ]
    }
   ],
   "source": [
    "def print_item(item = 0):\n",
    "    print(f\"ItemNum: {item+1}\")\n",
    "    print(f\"ERP's (n400): \\n{n400_control[0][item]}\")\n",
    "    print(f\"SPR: {spr_control[0][item]}\")\n",
    "\n",
    "print_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 90, 1)\n",
      "(1, 90, 26)\n",
      "(1, 90, 26)\n",
      "<class 'numpy.ndarray'>\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# check data shape\n",
    "print(spr_control.shape)\n",
    "print(n400_control.shape)\n",
    "print(p600_control.shape)\n",
    "\n",
    "# check data type\n",
    "print(type(spr_control))\n",
    "print(n400_control.dtype)\n",
    "print(p600_control.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((n400_control, p600_control), axis=0)\n",
    "y = np.reshape(spr_control, (90, 1, 1))\n",
    "\n",
    "# reshape x to have 90 in first dimension\n",
    "X = np.reshape(X, (90, X.shape[0], 26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (72, 2, 26)\n",
      "y_train shape: (72, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from keras.utils import get_custom_objects\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return 1 - SS_res / (SS_tot + K.epsilon())\n",
    "\n",
    "get_custom_objects().update({\"r_squared\": r_squared})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import Sequential\n",
    "from keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_87 (LSTM)              (None, 32)                7552      \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 128)               4224      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,577\n",
      "Trainable params: 88,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# make an rnn model that takes in the n400 and p600 data and predicts the spr data\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=(2, 26)))\n",
    "model.add(layers.LSTM(32, input_shape=(2, 26)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(16, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"relu\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mae\", metrics=['mae', 'mse', 'r_squared'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 93.7772 - mae: 93.7772 - mse: 15059.1309 - r_squared: -0.9183 - val_loss: 99.5105 - val_mae: 99.5105 - val_mse: 15262.7598 - val_r_squared: -0.2510\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 96.7691 - mae: 96.7691 - mse: 14194.7031 - r_squared: -0.8082 - val_loss: 99.5871 - val_mae: 99.5871 - val_mse: 15269.3936 - val_r_squared: -0.2516\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 86.8000 - mae: 86.8000 - mse: 13034.4785 - r_squared: -0.6604 - val_loss: 99.1248 - val_mae: 99.1248 - val_mse: 15189.2920 - val_r_squared: -0.2450\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 87.2183 - mae: 87.2183 - mse: 11995.5557 - r_squared: -0.5280 - val_loss: 99.4829 - val_mae: 99.4829 - val_mse: 15219.1240 - val_r_squared: -0.2474\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 83.9353 - mae: 83.9353 - mse: 11753.5381 - r_squared: -0.4972 - val_loss: 99.1306 - val_mae: 99.1306 - val_mse: 15161.6787 - val_r_squared: -0.2427\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 87.6944 - mae: 87.6944 - mse: 13119.0752 - r_squared: -0.6711 - val_loss: 99.1241 - val_mae: 99.1241 - val_mse: 15166.6182 - val_r_squared: -0.2431\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 84.5301 - mae: 84.5301 - mse: 12174.1162 - r_squared: -0.5508 - val_loss: 99.8770 - val_mae: 99.8770 - val_mse: 15232.3867 - val_r_squared: -0.2485\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 98.1619 - mae: 98.1619 - mse: 17417.8848 - r_squared: -1.2187 - val_loss: 100.4449 - val_mae: 100.4449 - val_mse: 15300.1338 - val_r_squared: -0.2541\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 83.8718 - mae: 83.8718 - mse: 11091.5684 - r_squared: -0.4129 - val_loss: 101.7809 - val_mae: 101.7809 - val_mse: 15484.2197 - val_r_squared: -0.2692\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 82.0809 - mae: 82.0809 - mse: 11292.1641 - r_squared: -0.4384 - val_loss: 103.2127 - val_mae: 103.2127 - val_mse: 15746.3682 - val_r_squared: -0.2907\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 81.3399 - mae: 81.3399 - mse: 11020.9307 - r_squared: -0.4039 - val_loss: 104.4302 - val_mae: 104.4302 - val_mse: 15983.6973 - val_r_squared: -0.3101\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 86.3493 - mae: 86.3493 - mse: 12826.4131 - r_squared: -0.6339 - val_loss: 104.1721 - val_mae: 104.1721 - val_mse: 15962.9287 - val_r_squared: -0.3084\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 77.7978 - mae: 77.7978 - mse: 10833.8389 - r_squared: -0.3800 - val_loss: 103.3132 - val_mae: 103.3132 - val_mse: 15866.2637 - val_r_squared: -0.3005\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 84.2973 - mae: 84.2973 - mse: 13058.0352 - r_squared: -0.6634 - val_loss: 102.5934 - val_mae: 102.5934 - val_mse: 15792.6436 - val_r_squared: -0.2944\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 75.2889 - mae: 75.2889 - mse: 9733.1777 - r_squared: -0.2398 - val_loss: 101.5295 - val_mae: 101.5295 - val_mse: 15670.1963 - val_r_squared: -0.2844\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 69.6909 - mae: 69.6909 - mse: 7457.1597 - r_squared: 0.0501 - val_loss: 100.7046 - val_mae: 100.7046 - val_mse: 15614.1221 - val_r_squared: -0.2798\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 77.8703 - mae: 77.8703 - mse: 11828.4648 - r_squared: -0.5067 - val_loss: 99.5817 - val_mae: 99.5817 - val_mse: 15534.9678 - val_r_squared: -0.2733\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 77.1915 - mae: 77.1915 - mse: 10389.6484 - r_squared: -0.3235 - val_loss: 97.3355 - val_mae: 97.3355 - val_mse: 15381.9219 - val_r_squared: -0.2608\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 78.8826 - mae: 78.8826 - mse: 10581.8486 - r_squared: -0.3479 - val_loss: 94.9367 - val_mae: 94.9367 - val_mse: 15287.4756 - val_r_squared: -0.2530\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 88.4441 - mae: 88.4441 - mse: 11662.4043 - r_squared: -0.4856 - val_loss: 92.7634 - val_mae: 92.7634 - val_mse: 15274.7344 - val_r_squared: -0.2520\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 95.1523 - mae: 95.1523 - mse: 13966.2158 - r_squared: -0.7790 - val_loss: 92.0637 - val_mae: 92.0637 - val_mse: 15267.0645 - val_r_squared: -0.2514\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 71.5704 - mae: 71.5704 - mse: 10218.6016 - r_squared: -0.3017 - val_loss: 91.3867 - val_mae: 91.3867 - val_mse: 15294.7012 - val_r_squared: -0.2536\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 79.3855 - mae: 79.3855 - mse: 10696.1748 - r_squared: -0.3625 - val_loss: 91.3042 - val_mae: 91.3042 - val_mse: 15305.3955 - val_r_squared: -0.2545\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 74.1754 - mae: 74.1754 - mse: 8445.6758 - r_squared: -0.0758 - val_loss: 91.3199 - val_mae: 91.3199 - val_mse: 15239.5039 - val_r_squared: -0.2491\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 76.5521 - mae: 76.5521 - mse: 10436.9014 - r_squared: -0.3295 - val_loss: 92.2232 - val_mae: 92.2232 - val_mse: 15138.4619 - val_r_squared: -0.2408\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 74.6097 - mae: 74.6097 - mse: 9035.8711 - r_squared: -0.1510 - val_loss: 94.5799 - val_mae: 94.5799 - val_mse: 15111.5254 - val_r_squared: -0.2386\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 74.1033 - mae: 74.1033 - mse: 9080.8486 - r_squared: -0.1567 - val_loss: 97.0267 - val_mae: 97.0267 - val_mse: 15232.0049 - val_r_squared: -0.2485\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 83.8639 - mae: 83.8639 - mse: 12072.7764 - r_squared: -0.5379 - val_loss: 98.6975 - val_mae: 98.6975 - val_mse: 15366.0869 - val_r_squared: -0.2595\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 80.0356 - mae: 80.0356 - mse: 10600.2227 - r_squared: -0.3503 - val_loss: 101.6275 - val_mae: 101.6275 - val_mse: 15755.3105 - val_r_squared: -0.2914\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 78.7100 - mae: 78.7100 - mse: 9500.2539 - r_squared: -0.2102 - val_loss: 103.1850 - val_mae: 103.1850 - val_mse: 15964.6289 - val_r_squared: -0.3085\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 83.3767 - mae: 83.3767 - mse: 12122.0215 - r_squared: -0.5441 - val_loss: 102.9375 - val_mae: 102.9375 - val_mse: 15858.7803 - val_r_squared: -0.2999\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 75.1627 - mae: 75.1627 - mse: 10162.5322 - r_squared: -0.2945 - val_loss: 101.1273 - val_mae: 101.1273 - val_mse: 15511.1240 - val_r_squared: -0.2714\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 79.7068 - mae: 79.7068 - mse: 9866.9082 - r_squared: -0.2569 - val_loss: 99.0500 - val_mae: 99.0500 - val_mse: 15241.9678 - val_r_squared: -0.2493\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 66.3102 - mae: 66.3102 - mse: 7737.1025 - r_squared: 0.0144 - val_loss: 97.2374 - val_mae: 97.2374 - val_mse: 15183.5146 - val_r_squared: -0.2445\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 55.6433 - mae: 55.6433 - mse: 6627.1777 - r_squared: 0.1558 - val_loss: 95.5484 - val_mae: 95.5484 - val_mse: 15197.9121 - val_r_squared: -0.2457\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 70.3343 - mae: 70.3343 - mse: 8446.9844 - r_squared: -0.0760 - val_loss: 94.9616 - val_mae: 94.9616 - val_mse: 15211.9541 - val_r_squared: -0.2468\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 78.4538 - mae: 78.4538 - mse: 9863.0039 - r_squared: -0.2564 - val_loss: 94.4681 - val_mae: 94.4681 - val_mse: 15159.7070 - val_r_squared: -0.2426\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 80.3684 - mae: 80.3684 - mse: 10923.1885 - r_squared: -0.3914 - val_loss: 93.8869 - val_mae: 93.8869 - val_mse: 15027.6562 - val_r_squared: -0.2317\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 82.5744 - mae: 82.5744 - mse: 11208.9678 - r_squared: -0.4278 - val_loss: 93.3526 - val_mae: 93.3526 - val_mse: 14910.6416 - val_r_squared: -0.2222\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 74.9777 - mae: 74.9777 - mse: 10562.5166 - r_squared: -0.3455 - val_loss: 92.7464 - val_mae: 92.7464 - val_mse: 14767.9531 - val_r_squared: -0.2105\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 72.6249 - mae: 72.6249 - mse: 9323.1514 - r_squared: -0.1876 - val_loss: 92.5032 - val_mae: 92.5032 - val_mse: 14633.9873 - val_r_squared: -0.1995\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 68.7386 - mae: 68.7386 - mse: 9437.3193 - r_squared: -0.2021 - val_loss: 92.8735 - val_mae: 92.8735 - val_mse: 14514.5020 - val_r_squared: -0.1897\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 80.2718 - mae: 80.2718 - mse: 10785.3555 - r_squared: -0.3739 - val_loss: 93.1618 - val_mae: 93.1618 - val_mse: 14486.5273 - val_r_squared: -0.1874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27c70e658b0>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=64, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "MSE: 8447.366241759839\n",
      "R^2: -0.2929320909621169\n",
      "\n",
      "First 5 predictions: \n",
      "pred: 412 actual: 595\n",
      "pred: 357 actual: 428\n",
      "pred: 356 actual: 425\n",
      "pred: 368 actual: 472\n",
      "pred: 400 actual: 432\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "# remove 1 dim from y_test to match pred\n",
    "y_test_ = np.squeeze(y_test, axis=1)\n",
    "pred = np.squeeze(pred, axis=1)\n",
    "\n",
    "mse = mean_squared_error(y_test_, pred)\n",
    "print(f\"\\nMSE: {mse}\")\n",
    "\n",
    "r_squared = r2_score(y_test_, pred)\n",
    "print(f\"R^2: {r_squared}\")\n",
    "\n",
    "print(\"\\nFirst 5 predictions: \")\n",
    "for i in range(min(len(pred), 5)):\n",
    "    print(f\"pred: {round(pred[i])}\", end=\" \")\n",
    "    print(f\"actual: {round(y_test_[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
